## TF-IDF Implementation on Enron Dataset

**Idea**: In order to get familiar with tf-idf in action, I have borrowed the Enron dataset as a starting point for understanding how powerful tf-idf can be. The Enron dataset consists of over 500,000 emails generated by employees of the Enron Corporation. The dataset was obtained by the Federal Energy Regulation Commission during its investigation of Enron's collapse. The dataset can be found here: https://www.kaggle.com/wcukierski/enron-email-dataset


### Methodology

1. Load the dataset.
2. Pre-process the dataset, extracting all the necessary fields and creating a pandas dataframe.
3. Pre-process the content of the emails by:
 - removing website urls
 - standardizing words
 - removing puncuation
 - removing all numbers
 - removing stop words
 - removing chat words
4. Applying CountVectorizer to see the frequency of words in each document. 
5. Apply TF-IDF to get the weighted word frequencies by applying the following formula: 
 - ''the tf-idf of term t is
    tf-idf(d, t) = tf(t) * idf(d, t), and the idf is computed as idf(d, t) = log [ n / df(d, t) ] + 1 (if ``smooth_idf=False``), where n is the total number of documents and df(d, t) is the document frequency; the document frequency is the number of documents d that contain term t. The effect of adding "1" to the idf in the equation above is that terms with zero idf, i.e., terms  that occur in all documents in a training set, will not be entirely ignored.'' (from scikit-learn documentation)


### Execution

Open the jupyter notebook named: NLP on Enron Data.ipynb. To run each cell, press Shift+Enter. Make sure to run them sequentially because each cell depends on the one before it. 

**Resources**: 

- To learn more about the Enron scandal: https://en.wikipedia.org/wiki/Enron_scandal
- Scikit-learn documentation: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer.get_feature_names